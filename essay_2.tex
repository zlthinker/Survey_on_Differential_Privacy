%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Thin Sectioned Essay
% LaTeX Template
% Version 1.0 (3/8/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original Author:
% Nicolas Diaz (nsdiaz@uc.cl) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a4paper, 11pt]{article} % Font size (can be 10pt, 11pt or 12pt) and paper size (remove a4paper for US letter paper)

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\usepackage{amsthm}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\usepackage[protrusion=true,expansion=true]{microtype} % Better typography
\usepackage{graphicx} % Required for including pictures
\usepackage{wrapfig} % Allows in-line images

\usepackage{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Required for accented characters
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default

\makeatletter
\renewcommand\@biblabel[1]{\textbf{#1.}} % Change the square brackets for each bibliography item from '[1]' to '1.'
\renewcommand{\@listI}{\itemsep=0pt} % Reduce the space between items in the itemize and enumerate environments and the bibliography

\renewcommand{\maketitle}{ % Customize the title - do not edit title and author name here, see the TITLE block below
\begin{flushright} % Right align
{\LARGE\@title} % Increase the font size of the title

\vspace{50pt} % Some vertical space between the title and author name

{\large\@author} % Author name
\\\@date % Date

\vspace{40pt} % Some vertical space between the author block and abstract
\end{flushright}
}

%----------------------------------------------------------------------------------------
%	TITLE
%----------------------------------------------------------------------------------------

\title{\textbf{Differential Privacy}\\ % Title
A Survery} % Subtitle

\author{\textsc{20398702 HU, Jiajun \\ ZHOU, Lei} % Author
\\{\textit{Department of Computer Science \& Engineering \\ The Hong Kong University of Science and Technology}}} % Institution

\date{\today} % Date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title section

%----------------------------------------------------------------------------------------
%	ABSTRACT AND KEYWORDS
%----------------------------------------------------------------------------------------

%\renewcommand{\abstractname}{Summary} % Uncomment to change the name of the abstract to something else

\begin{abstract}

\end{abstract}

\hspace*{3,6mm}\textit{Keywords:} differential privacy % Keywords

\vspace{30pt} % Some vertical space between the abstract and first section

%----------------------------------------------------------------------------------------
%	ESSAY BODY
%----------------------------------------------------------------------------------------

\section{Introduction}







%------------------------------------------------

\section{Differentail Privacy}

Over the past ten years, differentail privacy\cite{dwork2008differential, dwork2014algorithmic} has emerged to become one of the most powerful approaches to ensure data pricacy. Roughly speaking, differential privacy ensures that the removal or insertion of a single record does not significantly affect the outcome of any analysis conducted on the database, thus making it possible to prevent private information from exposing to attackers. It follows a rigorous mathematical deduction to prove it can reduce the risk of privacy breach while remaining the utility of the data. At the beginning of this section, we will illuminate the concept by leveraging a simple example. Then, we will give the mathematical definition of differential privay and introduce two privacy mechanisms to achieve it.

\subsection{A Simple Example}
Suppose you have access to a database that allows you to compute the total income of all resident in certain area. You know one of your friends, Mr. White is going to move to another area, so simply computing the total income of all resident before and after Mr. White's move would allow you to guess his real income. As shown in table \ref{table:1}, the total income of all residents before Mr.White's move is 50 million, while the total income of all residents after Mr.White's move is 49 million. One can compute the real income of Mr.White is 1 millon. So from this example we can see even though we are not allowed to retrieve the information of a particular person, we are still able to get the private informtion through certain opertions. So what could one do to stop this? In the next section, we wil see how differential privacy can help resolve this problem.


\begin{table}
	\begin{tabular}{||c||c||} 
		\hline
		Name & Annual Income  \\ [0.5ex] 
		\hline\hline
		Mr. Richard & 0.5 million  \\ 
		\hline
		Mr. White & 1 million \\
		\hline
		Mr. Brown & 2 million \\
		\hline
		Ms. Lee & 0.35 million \\
		\hline
		Ms. Jean & 0.6 million \\
		\hline
		... & ...  \\
		\hline
		\multicolumn{2}{||c||}{Total income = 50 million}\\
		\hline
	\end{tabular}
\quad\quad
\begin{tabular}{||c || c||} 
	\hline
	Name & Annual Income  \\ [0.5ex] 
	\hline\hline
	Mr. Richard & 0.5 million  \\ 
	\hline
      &  \\
	\hline
	Mr. Brown & 2 million \\
	\hline
	Ms. Lee & 0.35 million \\
	\hline
	Ms. Jean & 0.6 million \\
	\hline
	... & ...  \\
	\hline
	\multicolumn{2}{||c||}{Total income = 49 million}\\
	\hline
\end{tabular}
	\caption{The table before and after Mr. White's move. }
	\label{table:1}
\end{table}

\subsection{Definition of Differential Privacy}
Firstly, let us define some notations.
\theoremstyle{definition}
\begin{definition}{}
 $D$ and $D^\prime$ are databases, but they must differs on at most one row. 
\end{definition}
The reason why $D$ and $D^\prime$ is required to differ on one row is to simulate whether a particular record is in or not in the database.
\begin{definition}{}
$f(D)$ is a query on D
\end{definition}
Refer to the previous example, $f(D)$ is the total income of all residents in the database.
\begin{definition}{}
	$M(D)$ is the privacy mechanism, which is a randomized function that takes the database $D$ as inpiut, and release privatized information with respect to $f(D)$.
\end{definition}
Desiging privacy mechanism is a topic on its own\cite{mcsherry2007mechanism}. In this survery, we only consider Laplace Mechanism and Exponential Mechanism. Refer to the previous example, $M(D)$ is the privated total income obtained by adding random noise on the total income.
\begin{definition}{$\epsilon$ - differential privacy}
	A privacy mechanism $M$ gives $\epsilon$ - differential privacy if for all data sets $D$ and $D^\prime$ differing on at most one row, and all $C\in Range(M)$,
	\[  \frac{Pr[M(D) = C]}{Pr[M(D^\prime) = C]}< e^\epsilon \]
\end{definition}
$\epsilon - differential \ privacy$ is a special case of $(\epsilon,\delta) - differential \ privacy$\cite{dwork2011differential,dwork2006our} with $\delta = 0$. Typically, $(\epsilon,\delta) - differential \ privacy$ is simplified to $\epsilon - differential \ privacy$, so we only consider $\epsilon - differential \ privacy$ in this survey. $\epsilon - differential \ privacy$ says that the probability that the privatized result will be $C$ is nearly the same whether or not you are in the database, which means an adversary cannot infer with high confidence (controlled by $\epsilon$) whether the input database is $D$ or $D^\prime$. In the definition, $\epsilon$ is the privacy budget, which is a tradeoff that is used to balance the privacy of the result and it's utility. The smaller the $\epsilon$ is, the closer $Pr[M(D) = C]$ and $Pr[M(D^\prime) = C]$ are, and the stronger protection is. 
\subsection{Laplace Mechanism}
In this section, we will introduction one of the most popular privacy mechanisms - Laplace Mechanism\cite{dwork2006calibrating}. Laplace mechanism works particularly well when the query $f(D)\in R^n$ is a funtion mapping databases to (vectors of) real numbers. For example, when the query is a counting query, $f(D)$ is the number of records in the database.
\begin{definition}{Sensitivity of a Function}
For $f: D\rightarrow R^n$, the sensitivity of $f$ is 
	\[  \bigtriangleup f = max_{D, D\prime} ||f(D) - f(D\prime)||_n \]
	for all $D, D\prime$ differs on at most one row.
\end{definition}
Intutively, $\bigtriangleup f$ captures how much one person's data can affect the ouput. Taking the counting query as an example, $\bigtriangleup f = 1$ because adding or deleting a row of the database will only affect the number of records by 1. 

For simplicity, we only consider the case when $n=1$. Laplace Mechanism $M(D)$ privatizes the result by adding a 0-centered symmetric random noise, which is drawn from Laplace Distribution\cite{simon1774memoire} with parameter $\bigtriangleup f / \epsilon$,  on the true answer $f(D)$. So the probability density function of the random noise $x$ is
   \[ Pr[x] = \frac{\epsilon}{2\bigtriangleup f}e^{-\frac{|x|\epsilon}{\bigtriangleup f}}  \]
The probability density function of $M(D)$ is
  \[ Pr[M(D)] = Pr[x+f(D)] = \frac{\epsilon}{2\bigtriangleup f}e^{-\frac{|x-f(D)|\epsilon}{\bigtriangleup f}}  \]
  The mathematical proof that laplace mechnism yields a $\epsilon - differential \ privacy$ is straightforward. 
  \[ \frac{Pr[M(D) = C]}{Pr[M(D\prime = C)]} = \frac{\frac{\epsilon}{2\bigtriangleup f}e^{-\frac{|x-f(D)|\epsilon}{\bigtriangleup f}} }{\frac{\epsilon}{2\bigtriangleup f}e^{-\frac{|x-f(D\prime)|\epsilon}{\bigtriangleup f}} } = \frac{e^{-\frac{|x-f(D)|\epsilon}{\bigtriangleup f}} }{e^{-\frac{|x-f(D\prime)|\epsilon}{\bigtriangleup f}} } \] \[= e^{-\frac{|x-f(D)|\epsilon}{\bigtriangleup f} + \frac{|x-f(D\prime)|\epsilon}{\bigtriangleup f} } = e^{\frac{|f(D) - f(D\prime)|\epsilon}{\bigtriangleup f}} \leq e^\epsilon \]
  
So it concludes that laplace mechanism yields $\epsilon - differential \ privacy$
\subsection{Exponential Mechanism}

\section{Local Differential Privacy}
In traditional differential privacy\cite{dwork2008differential}, all sensitive information from a large number of respondents are gathered by a trusted and trustworthy curator, who further releases the statistical information of the underlying population to the public. The reponsibiliy to privatize information lies on the curator side. However, in Local Differential Privacy (LDP)\cite{gupta2013privately,kasiviswanathan2011can}, every respondent take the responsibility to privatize his or her data locally before sending to the curator. So in this setting, the curator will never have the access to the exact value of sensitive information, which protects not only the privacy of data contributors but also the curator itself against the potential risk of information leakage. The goal of LDP is two fold: (1) $\epsilon - differential \ privacy$ must be satisfied on each user side. (2) the curator should be able to compute accurate statistics from the noisy data received from the user side. It turns out that traditional differential privacy mechanisms are not adequate enough to address the LDP problems. In the following, we overview several typical LDP solutions.
\subsection{Randomized Response}
Rendomized Response (RR)\cite{erlingsson2014rappor} asks each user with a sensitive question whose answer must be "yes" or "no". For example, "do you like Donald Trump?". The user flips a coin to decide which answer to give. The user gives his true answer when the coin turns head, and gives the opposite answer when the coin turns tail. However, in RR, instead of using a fair coin, we use a biased coin. It turns head with probability $p$, and turns tail with probability $1-p$. It turns out that $\epsilon - differential \ privacy$ can be satisfied with the following value of p:
\[ p = \frac{e^\epsilon}{1+e^\epsilon} \]
The goal of the curator is to give the estimated percentage of "yes" given the noisy answers. Suppose the percentage of "yes" given the noisy answer is $c$, the corrected version of the result $c^\prime$ is:
\[ c^\prime = c \times c_{e}, where \ c_{e} = \frac{1}{1-2p}\]
The limitation of RR is that it can only be applied to the problem with binary answer.
\subsection{RAPPOR}
RAPPOR\cite{erlingsson2014rappor,fanti2016building} extends RR\cite{erlingsson2014rappor} to more complex data types. Suppose there are $n$ users and $d$ items, each user can own exactly one item. To be more specific, let us define $u_i$, where $i=1 \ to \ n$, as the $i_{th}$ user. $v_i$, where $i=1 \ to \ n$, is a vector with length $d$ of $u_i$. All the coordinates of $v_i$ are 0 except the $j_{th}$ coordinate, which is 1, if $u_i$ owns item $j$. The goal of the corator is the same as in RR, which is to compute the frequency of each item. User $u_i$ applies RR independently on each coordinate of $v_i$ with a biased coin with probability $p$ (the sensitivity of any query function $f$ is 2 because any vector contains a single coordinate of 1, hence the maximum difference between $f(D)$ and $f(D^\prime)$ is 2):
\[ p = \frac{e^{\frac{\epsilon}{2}}}{1+e^{\frac{\epsilon}{2}}} \]
The limitation of RAPPOR is that it can cause huge communication overhead because each user has to send a vector with lengh $d$, which can be extremly large in some cases (e.g. the number of email accounts of all users).

\subsection{Succinct histogram}
Succinct histogram (SH)\cite{bassily2015local} addresses the communication overhead led by RAPPOR\cite{erlingsson2014rappor,fanti2016building}. Basically, the problem setting of SH remains the same with RAPPOR, i.e. each user $u_i$ owns a vector $v_i$ of length $d$, with only one coordinate to be 1 and all the others to be 0. The goal of the curator is also to estimate the frequency of each item. The main idea behind SH is instead of sending $d$ coordinates every time, every user only randomly pick one coordinate and report it to the curator. In this way, the communication overhead drops from $O(d)$ to $O(1)$. 
\subsection{LDPMiner}
The above mentioned solutions pose too much limitations on the data types. In order to cope with complex data types, Zhan et al. proposed LDPMiner\cite{qin2016heavy} to address the heavy hitters over set-valued data. Suppose there are $n$ users and $d$ items, and each user can own exactly $l$ items. If the number of the items a user owns is smaller than $l$, some dummy items are added to fill the set. If the number of the items a user owns is greater than $l$, $l$ randomly picked items are considered in the set. The frequency of the item is the portion of users owning this item. The general goal of the curator is to find the top-k most frequent items with the highest frequency. LDPMiner proposes a two-phase solution. The main idea is to firstly filter the items and select $O(k)$ candidate heavy hitters in the first phase, and then focuses on refining the frequecy estimates of these candidates in the second phase. LDPMiner splits the total privay budget $\epsilon$ as $\epsilon_1$ and $\epsilon_2$, which is assigned to phase one and phase two respectively. According to sequential composability\cite{mcsherry2009privacy}, the whole process satisfies $\epsilon - differential \ privacy$.
%------------------------------------------------

\section*{Conclusion}





%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliographystyle{unsrt}

\bibliography{sample}

%----------------------------------------------------------------------------------------

\end{document}